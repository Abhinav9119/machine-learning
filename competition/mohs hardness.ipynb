{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7be5655-79ee-46fa-8116-ee7650c0f027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score,mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn. linear_model import Ridge,Lasso,ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c375196-294b-4950-9443-2b2c4b2bb00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r\"C:\\Users\\dbda\\Desktop\\MACHINE LEARNING\\competition\")\n",
    "df=pd.read_csv(\"train.csv\")\n",
    "df.set_index(\"id\", inplace = True)\n",
    "\n",
    "x=df.drop(\"Hardness\",axis=1)\n",
    "y=df[\"Hardness\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "082aaf33-e84b-49cd-8873-6fa50e1d18cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10407 entries, 0 to 10406\n",
      "Data columns (total 12 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   allelectrons_Total     10407 non-null  float64\n",
      " 1   density_Total          10407 non-null  float64\n",
      " 2   allelectrons_Average   10407 non-null  float64\n",
      " 3   val_e_Average          10407 non-null  float64\n",
      " 4   atomicweight_Average   10407 non-null  float64\n",
      " 5   ionenergy_Average      10407 non-null  float64\n",
      " 6   el_neg_chi_Average     10407 non-null  float64\n",
      " 7   R_vdw_element_Average  10407 non-null  float64\n",
      " 8   R_cov_element_Average  10407 non-null  float64\n",
      " 9   zaratio_Average        10407 non-null  float64\n",
      " 10  density_Average        10407 non-null  float64\n",
      " 11  Hardness               10407 non-null  float64\n",
      "dtypes: float64(12)\n",
      "memory usage: 1.0 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8adc4d6c-f0ad-4f2a-bdf3-fb62819e8d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold,cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7eec841a-19ef-4ae7-ab34-8376ca0f97b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.25}\n",
      "0.24214792962324613\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Hardness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10408.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10409.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10410.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10411.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6934</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.499921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6935</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.491445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6936</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.461584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6937</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.351898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6938</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.677486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13878 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  Hardness\n",
       "0     10407.0       NaN\n",
       "1     10408.0       NaN\n",
       "2     10409.0       NaN\n",
       "3     10410.0       NaN\n",
       "4     10411.0       NaN\n",
       "...       ...       ...\n",
       "6934      NaN  5.499921\n",
       "6935      NaN  4.491445\n",
       "6936      NaN  5.461584\n",
       "6937      NaN  4.351898\n",
       "6938      NaN  1.677486\n",
       "\n",
       "[13878 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas=np.arange(0,10,0.25)\n",
    "params={\"alpha\":alphas}\n",
    "ridge=Ridge()\n",
    "kfold=KFold(n_splits=5,shuffle=True,random_state=24)\n",
    "gcv=GridSearchCV(ridge,param_grid=params,cv=kfold)  #to get minimum value of mean squared error \n",
    "gcv.fit(x,y)\n",
    "print(gcv.best_params_)\n",
    "print(gcv.best_score_)\n",
    "\n",
    "\n",
    "best_model=gcv.best_estimator_\n",
    "tst=pd.read_csv(\"test.csv\")\n",
    "df_submission=tst[[\"id\"]]\n",
    "\n",
    "tst.set_index(\"id\", inplace = True)\n",
    "\n",
    "pred_str=best_model.predict(tst)\n",
    "\n",
    "df2 = pd.DataFrame(pred_str, columns =[\"Hardness\"])\n",
    "df3=pd.concat([df_submission,df2])\n",
    "#df3=df3[df_submission[\"id\"],df2[\"Hardness\"]]\n",
    "df2\n",
    "df_submission=pd.concat([df_submission,df2])\n",
    "df_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04131731-6192-4e39-bfa2-e4c081353f97",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gcv_r' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m best_model\u001b[38;5;241m=\u001b[39m\u001b[43mgcv_r\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gcv_r' is not defined"
     ]
    }
   ],
   "source": [
    "best_model=gcv_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "374d89e2-44ee-4ebb-be9c-5457dfca066d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>allelectrons_Total</th>\n",
       "      <th>density_Total</th>\n",
       "      <th>allelectrons_Average</th>\n",
       "      <th>val_e_Average</th>\n",
       "      <th>atomicweight_Average</th>\n",
       "      <th>ionenergy_Average</th>\n",
       "      <th>el_neg_chi_Average</th>\n",
       "      <th>R_vdw_element_Average</th>\n",
       "      <th>R_cov_element_Average</th>\n",
       "      <th>zaratio_Average</th>\n",
       "      <th>density_Average</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10407</th>\n",
       "      <td>884.0</td>\n",
       "      <td>121.420000</td>\n",
       "      <td>35.360000</td>\n",
       "      <td>5.280000</td>\n",
       "      <td>82.561240</td>\n",
       "      <td>9.370384</td>\n",
       "      <td>2.298000</td>\n",
       "      <td>1.907200</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.461899</td>\n",
       "      <td>1.79459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10408</th>\n",
       "      <td>90.0</td>\n",
       "      <td>9.931960</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>39.568056</td>\n",
       "      <td>12.086300</td>\n",
       "      <td>2.868000</td>\n",
       "      <td>1.652000</td>\n",
       "      <td>0.864000</td>\n",
       "      <td>0.476196</td>\n",
       "      <td>1.41194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10409</th>\n",
       "      <td>116.0</td>\n",
       "      <td>7.767992</td>\n",
       "      <td>11.600000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>23.231818</td>\n",
       "      <td>11.023840</td>\n",
       "      <td>2.644000</td>\n",
       "      <td>1.794000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.499514</td>\n",
       "      <td>0.78834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10410</th>\n",
       "      <td>100.0</td>\n",
       "      <td>9.107996</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>20.298893</td>\n",
       "      <td>12.086300</td>\n",
       "      <td>2.828000</td>\n",
       "      <td>1.662000</td>\n",
       "      <td>0.792000</td>\n",
       "      <td>0.495796</td>\n",
       "      <td>1.20466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10411</th>\n",
       "      <td>55.0</td>\n",
       "      <td>4.030000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>22.977675</td>\n",
       "      <td>11.280950</td>\n",
       "      <td>2.455000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.476095</td>\n",
       "      <td>0.93456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17341</th>\n",
       "      <td>446.0</td>\n",
       "      <td>36.135392</td>\n",
       "      <td>9.636364</td>\n",
       "      <td>4.636364</td>\n",
       "      <td>19.689448</td>\n",
       "      <td>11.045515</td>\n",
       "      <td>2.768636</td>\n",
       "      <td>1.769697</td>\n",
       "      <td>0.871818</td>\n",
       "      <td>0.498702</td>\n",
       "      <td>0.11548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17342</th>\n",
       "      <td>36.0</td>\n",
       "      <td>3.550000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>36.068500</td>\n",
       "      <td>8.236600</td>\n",
       "      <td>1.790000</td>\n",
       "      <td>2.055000</td>\n",
       "      <td>1.390000</td>\n",
       "      <td>0.499000</td>\n",
       "      <td>1.35045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17343</th>\n",
       "      <td>68.0</td>\n",
       "      <td>4.545328</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>22.688853</td>\n",
       "      <td>10.938358</td>\n",
       "      <td>2.876667</td>\n",
       "      <td>1.713333</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.499074</td>\n",
       "      <td>0.73425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17344</th>\n",
       "      <td>40.0</td>\n",
       "      <td>2.334164</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>13.016128</td>\n",
       "      <td>12.700467</td>\n",
       "      <td>2.770000</td>\n",
       "      <td>1.476667</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.663797</td>\n",
       "      <td>0.51227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17345</th>\n",
       "      <td>134.0</td>\n",
       "      <td>17.590000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>167.400000</td>\n",
       "      <td>8.213150</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>2.040000</td>\n",
       "      <td>1.410000</td>\n",
       "      <td>0.401635</td>\n",
       "      <td>0.44035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6939 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       allelectrons_Total  density_Total  allelectrons_Average  val_e_Average  \\\n",
       "id                                                                              \n",
       "10407               884.0     121.420000             35.360000       5.280000   \n",
       "10408                90.0       9.931960             18.000000       5.600000   \n",
       "10409               116.0       7.767992             11.600000       4.800000   \n",
       "10410               100.0       9.107996             10.000000       4.800000   \n",
       "10411                55.0       4.030000             11.000000       4.000000   \n",
       "...                   ...            ...                   ...            ...   \n",
       "17341               446.0      36.135392              9.636364       4.636364   \n",
       "17342                36.0       3.550000             18.000000       4.000000   \n",
       "17343                68.0       4.545328             11.333333       5.333333   \n",
       "17344                40.0       2.334164              6.666667       4.000000   \n",
       "17345               134.0      17.590000             67.000000       5.000000   \n",
       "\n",
       "       atomicweight_Average  ionenergy_Average  el_neg_chi_Average  \\\n",
       "id                                                                   \n",
       "10407             82.561240           9.370384            2.298000   \n",
       "10408             39.568056          12.086300            2.868000   \n",
       "10409             23.231818          11.023840            2.644000   \n",
       "10410             20.298893          12.086300            2.828000   \n",
       "10411             22.977675          11.280950            2.455000   \n",
       "...                     ...                ...                 ...   \n",
       "17341             19.689448          11.045515            2.768636   \n",
       "17342             36.068500           8.236600            1.790000   \n",
       "17343             22.688853          10.938358            2.876667   \n",
       "17344             13.016128          12.700467            2.770000   \n",
       "17345            167.400000           8.213150            1.950000   \n",
       "\n",
       "       R_vdw_element_Average  R_cov_element_Average  zaratio_Average  \\\n",
       "id                                                                     \n",
       "10407               1.907200               1.200000         0.461899   \n",
       "10408               1.652000               0.864000         0.476196   \n",
       "10409               1.794000               0.960000         0.499514   \n",
       "10410               1.662000               0.792000         0.495796   \n",
       "10411               1.750000               0.893333         0.476095   \n",
       "...                      ...                    ...              ...   \n",
       "17341               1.769697               0.871818         0.498702   \n",
       "17342               2.055000               1.390000         0.499000   \n",
       "17343               1.713333               0.916667         0.499074   \n",
       "17344               1.476667               0.616667         0.663797   \n",
       "17345               2.040000               1.410000         0.401635   \n",
       "\n",
       "       density_Average  \n",
       "id                      \n",
       "10407          1.79459  \n",
       "10408          1.41194  \n",
       "10409          0.78834  \n",
       "10410          1.20466  \n",
       "10411          0.93456  \n",
       "...                ...  \n",
       "17341          0.11548  \n",
       "17342          1.35045  \n",
       "17343          0.73425  \n",
       "17344          0.51227  \n",
       "17345          0.44035  \n",
       "\n",
       "[6939 rows x 11 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1092cb9f-3e20-460e-b91b-2f9c7b6ce5b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6bcfaeb5-f5ce-49d0-9fb9-a1204e8fd1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.803e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.919e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.926e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.768e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.945e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.0}\n",
      "0.24214703163526088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.109e+04, tolerance: 2.939e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "alphas=np.arange(0,10,0.25)\n",
    "params={\"alpha\":alphas}\n",
    "ls=Lasso()\n",
    "kfold=KFold(n_splits=5,shuffle=True,random_state=24)\n",
    "gcv=GridSearchCV(ls,param_grid=params,cv=kfold)\n",
    "gcv.fit(x,y)\n",
    "print(gcv.best_params_)\n",
    "print(gcv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66ce4ee5-b28e-4d66-8e83-efe64d70f940",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.803e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.919e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.926e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.768e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.945e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.803e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.919e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.926e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.768e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.945e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.803e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.919e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.926e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.768e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.945e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.803e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.919e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.926e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.768e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.945e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.803e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.919e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.926e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.768e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.945e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.803e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.919e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.926e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.768e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.945e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.803e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.919e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.926e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.768e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.945e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.803e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.919e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.926e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.768e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.945e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.803e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.919e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.926e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.768e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.945e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.803e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.919e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.926e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.768e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.945e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.485e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.549e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.604e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.384e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.608e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.566e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.624e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.685e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.456e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.683e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.610e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.665e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.728e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.495e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.723e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.639e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.692e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.757e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.521e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.748e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.660e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.711e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.778e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.540e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.767e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.677e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.726e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.795e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.554e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.781e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.690e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.738e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.808e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.566e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.793e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.701e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.748e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.819e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.576e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.802e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.710e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.757e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.828e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.584e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.810e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.718e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.764e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.836e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.591e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.817e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.725e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.771e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.843e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.597e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.823e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.732e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.776e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.849e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.602e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.828e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.737e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.781e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.854e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.607e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.833e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.742e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.786e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.859e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.612e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.838e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.747e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.790e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.864e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.616e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.841e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.751e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.794e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.868e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.619e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.845e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.755e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.798e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.872e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.623e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.848e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.759e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.801e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.875e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.626e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.851e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.762e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.804e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.878e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.629e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.854e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.765e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.807e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.881e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.631e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.857e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.768e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.810e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.884e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.634e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.860e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.771e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.812e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.887e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.636e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.862e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.773e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.814e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.890e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.639e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.864e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.776e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.817e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.892e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.641e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.866e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.778e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.819e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.894e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.643e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.868e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.780e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.821e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.896e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.645e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.870e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.782e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.823e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.898e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.647e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.872e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.784e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.825e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.900e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.648e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.874e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.786e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.827e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.902e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.650e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.876e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.788e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.828e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.904e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.652e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.877e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.790e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.830e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.906e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.653e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.879e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.792e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.831e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.908e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.655e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.880e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.793e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.833e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.909e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.656e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.882e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.795e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.835e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.911e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.658e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.883e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.796e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.836e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.912e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.659e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.885e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.798e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.837e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.914e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.661e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.886e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.799e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.839e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.915e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.662e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.887e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.801e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.840e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.917e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.663e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.888e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.802e+03, tolerance: 2.345e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.841e+03, tolerance: 2.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.918e+03, tolerance: 2.358e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.664e+03, tolerance: 2.334e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.890e+03, tolerance: 2.360e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "0.24214703163526088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dbda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.109e+04, tolerance: 2.939e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "alphas=np.arange(0,10,0.25)\n",
    "l1=np.arange(0,1,0.1)\n",
    "params={\"alpha\":alphas,\"l1_ratio\":l1}\n",
    "e1=ElasticNet()\n",
    "kfold=KFold(n_splits=5,shuffle=True,random_state=24)\n",
    "gcv=GridSearchCV(e1,param_grid=params,cv=kfold)\n",
    "gcv.fit(x,y)\n",
    "print(gcv.best_params_)\n",
    "print(gcv.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6072d06-ab72-4ec8-a9ed-751720f6b2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "{'alpha': 0.25}\n",
    "0.2419918874380274\n",
    "\n",
    "t_df=pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "30546cd4-6ef8-4606-b52e-4a9dcd839320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6939 entries, 0 to 6938\n",
      "Data columns (total 12 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   id                     6939 non-null   int64  \n",
      " 1   allelectrons_Total     6939 non-null   float64\n",
      " 2   density_Total          6939 non-null   float64\n",
      " 3   allelectrons_Average   6939 non-null   float64\n",
      " 4   val_e_Average          6939 non-null   float64\n",
      " 5   atomicweight_Average   6939 non-null   float64\n",
      " 6   ionenergy_Average      6939 non-null   float64\n",
      " 7   el_neg_chi_Average     6939 non-null   float64\n",
      " 8   R_vdw_element_Average  6939 non-null   float64\n",
      " 9   R_cov_element_Average  6939 non-null   float64\n",
      " 10  zaratio_Average        6939 non-null   float64\n",
      " 11  density_Average        6939 non-null   float64\n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 650.7 KB\n"
     ]
    }
   ],
   "source": [
    "t_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c3a0d5-ba74-45e8-9e9b-0b0a2cfc55c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#do it at home\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea651b1-b3e1-4d38-a0bb-7e862a1e77d6",
   "metadata": {},
   "source": [
    "# using KNN REGRESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90944084-f5bb-459c-aec4-466ee92cafde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92b11a13-0f45-4927-8ff1-0844c6ce8344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 117 candidates, totalling 585 fits\n",
      "[CV 1/5] END .....KNN__n_neighbors=1, SCL=None;, score=-0.800 total time=   0.0s\n",
      "[CV 2/5] END .....KNN__n_neighbors=1, SCL=None;, score=-0.800 total time=   0.0s\n",
      "[CV 3/5] END .....KNN__n_neighbors=1, SCL=None;, score=-0.700 total time=   0.0s\n",
      "[CV 4/5] END .....KNN__n_neighbors=1, SCL=None;, score=-0.700 total time=   0.0s\n",
      "[CV 5/5] END .....KNN__n_neighbors=1, SCL=None;, score=-0.800 total time=   0.0s\n",
      "[CV 1/5] END KNN__n_neighbors=1, SCL=StandardScaler();, score=-0.700 total time=   0.1s\n",
      "[CV 2/5] END KNN__n_neighbors=1, SCL=StandardScaler();, score=-0.800 total time=   0.1s\n",
      "[CV 3/5] END KNN__n_neighbors=1, SCL=StandardScaler();, score=-0.700 total time=   0.1s\n",
      "[CV 4/5] END KNN__n_neighbors=1, SCL=StandardScaler();, score=-0.500 total time=   0.0s\n",
      "[CV 5/5] END KNN__n_neighbors=1, SCL=StandardScaler();, score=-0.800 total time=   0.1s\n",
      "[CV 1/5] END KNN__n_neighbors=1, SCL=MinMaxScaler();, score=-0.700 total time=   0.0s\n",
      "[CV 2/5] END KNN__n_neighbors=1, SCL=MinMaxScaler();, score=-0.800 total time=   0.0s\n",
      "[CV 3/5] END KNN__n_neighbors=1, SCL=MinMaxScaler();, score=-0.800 total time=   0.0s\n",
      "[CV 4/5] END KNN__n_neighbors=1, SCL=MinMaxScaler();, score=-0.700 total time=   0.0s\n",
      "[CV 5/5] END KNN__n_neighbors=1, SCL=MinMaxScaler();, score=-0.800 total time=   0.1s\n",
      "[CV 1/5] END .....KNN__n_neighbors=2, SCL=None;, score=-0.800 total time=   0.0s\n",
      "[CV 2/5] END .....KNN__n_neighbors=2, SCL=None;, score=-0.850 total time=   0.0s\n",
      "[CV 3/5] END .....KNN__n_neighbors=2, SCL=None;, score=-0.750 total time=   0.0s\n",
      "[CV 4/5] END .....KNN__n_neighbors=2, SCL=None;, score=-0.750 total time=   0.0s\n",
      "[CV 5/5] END .....KNN__n_neighbors=2, SCL=None;, score=-0.800 total time=   0.0s\n",
      "[CV 1/5] END KNN__n_neighbors=2, SCL=StandardScaler();, score=-0.750 total time=   0.1s\n",
      "[CV 2/5] END KNN__n_neighbors=2, SCL=StandardScaler();, score=-0.750 total time=   0.1s\n",
      "[CV 3/5] END KNN__n_neighbors=2, SCL=StandardScaler();, score=-0.750 total time=   0.1s\n",
      "[CV 4/5] END KNN__n_neighbors=2, SCL=StandardScaler();, score=-0.750 total time=   0.1s\n",
      "[CV 5/5] END KNN__n_neighbors=2, SCL=StandardScaler();, score=-0.800 total time=   0.1s\n",
      "[CV 1/5] END KNN__n_neighbors=2, SCL=MinMaxScaler();, score=-0.750 total time=   0.0s\n",
      "[CV 2/5] END KNN__n_neighbors=2, SCL=MinMaxScaler();, score=-0.775 total time=   0.0s\n",
      "[CV 3/5] END KNN__n_neighbors=2, SCL=MinMaxScaler();, score=-0.750 total time=   0.1s\n",
      "[CV 4/5] END KNN__n_neighbors=2, SCL=MinMaxScaler();, score=-0.750 total time=   0.0s\n",
      "[CV 5/5] END KNN__n_neighbors=2, SCL=MinMaxScaler();, score=-0.750 total time=   0.0s\n",
      "[CV 1/5] END .....KNN__n_neighbors=3, SCL=None;, score=-0.800 total time=   0.0s\n",
      "[CV 2/5] END .....KNN__n_neighbors=3, SCL=None;, score=-0.800 total time=   0.0s\n",
      "[CV 3/5] END .....KNN__n_neighbors=3, SCL=None;, score=-0.700 total time=   0.0s\n",
      "[CV 4/5] END .....KNN__n_neighbors=3, SCL=None;, score=-0.833 total time=   0.0s\n",
      "[CV 5/5] END .....KNN__n_neighbors=3, SCL=None;, score=-0.833 total time=   0.0s\n",
      "[CV 1/5] END KNN__n_neighbors=3, SCL=StandardScaler();, score=-0.700 total time=   0.1s\n",
      "[CV 2/5] END KNN__n_neighbors=3, SCL=StandardScaler();, score=-0.733 total time=   0.1s\n",
      "[CV 3/5] END KNN__n_neighbors=3, SCL=StandardScaler();, score=-0.767 total time=   0.1s\n",
      "[CV 4/5] END KNN__n_neighbors=3, SCL=StandardScaler();, score=-0.733 total time=   0.1s\n",
      "[CV 5/5] END KNN__n_neighbors=3, SCL=StandardScaler();, score=-0.767 total time=   0.1s\n",
      "[CV 1/5] END KNN__n_neighbors=3, SCL=MinMaxScaler();, score=-0.700 total time=   0.1s\n",
      "[CV 2/5] END KNN__n_neighbors=3, SCL=MinMaxScaler();, score=-0.733 total time=   0.1s\n",
      "[CV 3/5] END KNN__n_neighbors=3, SCL=MinMaxScaler();, score=-0.800 total time=   0.1s\n",
      "[CV 4/5] END KNN__n_neighbors=3, SCL=MinMaxScaler();, score=-0.800 total time=   0.0s\n",
      "[CV 5/5] END KNN__n_neighbors=3, SCL=MinMaxScaler();, score=-0.767 total time=   0.1s\n",
      "[CV 1/5] END .....KNN__n_neighbors=4, SCL=None;, score=-0.750 total time=   0.0s\n",
      "[CV 2/5] END .....KNN__n_neighbors=4, SCL=None;, score=-0.775 total time=   0.0s\n",
      "[CV 3/5] END .....KNN__n_neighbors=4, SCL=None;, score=-0.725 total time=   0.0s\n",
      "[CV 4/5] END .....KNN__n_neighbors=4, SCL=None;, score=-0.775 total time=   0.0s\n",
      "[CV 5/5] END .....KNN__n_neighbors=4, SCL=None;, score=-0.775 total time=   0.0s\n",
      "[CV 1/5] END KNN__n_neighbors=4, SCL=StandardScaler();, score=-0.675 total time=   0.1s\n",
      "[CV 2/5] END KNN__n_neighbors=4, SCL=StandardScaler();, score=-0.762 total time=   0.1s\n",
      "[CV 3/5] END KNN__n_neighbors=4, SCL=StandardScaler();, score=-0.750 total time=   0.1s\n",
      "[CV 4/5] END KNN__n_neighbors=4, SCL=StandardScaler();, score=-0.725 total time=   0.1s\n",
      "[CV 5/5] END KNN__n_neighbors=4, SCL=StandardScaler();, score=-0.725 total time=   0.1s\n",
      "[CV 1/5] END KNN__n_neighbors=4, SCL=MinMaxScaler();, score=-0.750 total time=   0.1s\n",
      "[CV 2/5] END KNN__n_neighbors=4, SCL=MinMaxScaler();, score=-0.750 total time=   0.1s\n",
      "[CV 3/5] END KNN__n_neighbors=4, SCL=MinMaxScaler();, score=-0.775 total time=   0.1s\n",
      "[CV 4/5] END KNN__n_neighbors=4, SCL=MinMaxScaler();, score=-0.750 total time=   0.1s\n",
      "[CV 5/5] END KNN__n_neighbors=4, SCL=MinMaxScaler();, score=-0.750 total time=   0.1s\n",
      "[CV 1/5] END .....KNN__n_neighbors=5, SCL=None;, score=-0.760 total time=   0.0s\n",
      "[CV 2/5] END .....KNN__n_neighbors=5, SCL=None;, score=-0.760 total time=   0.0s\n",
      "[CV 3/5] END .....KNN__n_neighbors=5, SCL=None;, score=-0.740 total time=   0.0s\n",
      "[CV 4/5] END .....KNN__n_neighbors=5, SCL=None;, score=-0.760 total time=   0.0s\n",
      "[CV 5/5] END .....KNN__n_neighbors=5, SCL=None;, score=-0.760 total time=   0.0s\n",
      "[CV 1/5] END KNN__n_neighbors=5, SCL=StandardScaler();, score=-0.700 total time=   0.1s\n",
      "[CV 2/5] END KNN__n_neighbors=5, SCL=StandardScaler();, score=-0.750 total time=   0.1s\n",
      "[CV 3/5] END KNN__n_neighbors=5, SCL=StandardScaler();, score=-0.740 total time=   0.2s\n",
      "[CV 4/5] END KNN__n_neighbors=5, SCL=StandardScaler();, score=-0.700 total time=   0.1s\n",
      "[CV 5/5] END KNN__n_neighbors=5, SCL=StandardScaler();, score=-0.700 total time=   0.1s\n",
      "[CV 1/5] END KNN__n_neighbors=5, SCL=MinMaxScaler();, score=-0.700 total time=   0.1s\n",
      "[CV 2/5] END KNN__n_neighbors=5, SCL=MinMaxScaler();, score=-0.740 total time=   0.1s\n",
      "[CV 3/5] END KNN__n_neighbors=5, SCL=MinMaxScaler();, score=-0.780 total time=   0.1s\n",
      "[CV 4/5] END KNN__n_neighbors=5, SCL=MinMaxScaler();, score=-0.780 total time=   0.1s\n",
      "[CV 5/5] END KNN__n_neighbors=5, SCL=MinMaxScaler();, score=-0.720 total time=   0.1s\n",
      "[CV 1/5] END .....KNN__n_neighbors=6, SCL=None;, score=-0.750 total time=   0.0s\n",
      "[CV 2/5] END .....KNN__n_neighbors=6, SCL=None;, score=-0.767 total time=   0.0s\n",
      "[CV 3/5] END .....KNN__n_neighbors=6, SCL=None;, score=-0.733 total time=   0.0s\n",
      "[CV 4/5] END .....KNN__n_neighbors=6, SCL=None;, score=-0.767 total time=   0.0s\n",
      "[CV 5/5] END .....KNN__n_neighbors=6, SCL=None;, score=-0.750 total time=   0.0s\n",
      "[CV 1/5] END KNN__n_neighbors=6, SCL=StandardScaler();, score=-0.683 total time=   0.1s\n",
      "[CV 2/5] END KNN__n_neighbors=6, SCL=StandardScaler();, score=-0.750 total time=   0.2s\n",
      "[CV 3/5] END KNN__n_neighbors=6, SCL=StandardScaler();, score=-0.733 total time=   0.1s\n",
      "[CV 4/5] END KNN__n_neighbors=6, SCL=StandardScaler();, score=-0.700 total time=   0.1s\n",
      "[CV 5/5] END KNN__n_neighbors=6, SCL=StandardScaler();, score=-0.717 total time=   0.1s\n",
      "[CV 1/5] END KNN__n_neighbors=6, SCL=MinMaxScaler();, score=-0.683 total time=   0.1s\n",
      "[CV 2/5] END KNN__n_neighbors=6, SCL=MinMaxScaler();, score=-0.750 total time=   0.0s\n",
      "[CV 3/5] END KNN__n_neighbors=6, SCL=MinMaxScaler();, score=-0.733 total time=   0.1s\n",
      "[CV 4/5] END KNN__n_neighbors=6, SCL=MinMaxScaler();, score=-0.750 total time=   0.1s\n",
      "[CV 5/5] END KNN__n_neighbors=6, SCL=MinMaxScaler();, score=-0.700 total time=   0.1s\n",
      "[CV 1/5] END .....KNN__n_neighbors=7, SCL=None;, score=-0.743 total time=   0.0s\n",
      "[CV 2/5] END .....KNN__n_neighbors=7, SCL=None;, score=-0.757 total time=   0.0s\n",
      "[CV 3/5] END .....KNN__n_neighbors=7, SCL=None;, score=-0.729 total time=   0.0s\n",
      "[CV 4/5] END .....KNN__n_neighbors=7, SCL=None;, score=-0.771 total time=   0.0s\n",
      "[CV 5/5] END .....KNN__n_neighbors=7, SCL=None;, score=-0.743 total time=   0.0s\n",
      "[CV 1/5] END KNN__n_neighbors=7, SCL=StandardScaler();, score=-0.671 total time=   0.1s\n",
      "[CV 2/5] END KNN__n_neighbors=7, SCL=StandardScaler();, score=-0.736 total time=   0.2s\n",
      "[CV 3/5] END KNN__n_neighbors=7, SCL=StandardScaler();, score=-0.714 total time=   0.1s\n",
      "[CV 4/5] END KNN__n_neighbors=7, SCL=StandardScaler();, score=-0.700 total time=   0.1s\n",
      "[CV 5/5] END KNN__n_neighbors=7, SCL=StandardScaler();, score=-0.714 total time=   0.2s\n",
      "[CV 1/5] END KNN__n_neighbors=7, SCL=MinMaxScaler();, score=-0.686 total time=   0.1s\n",
      "[CV 2/5] END KNN__n_neighbors=7, SCL=MinMaxScaler();, score=-0.757 total time=   0.1s\n",
      "[CV 3/5] END KNN__n_neighbors=7, SCL=MinMaxScaler();, score=-0.729 total time=   0.1s\n",
      "[CV 4/5] END KNN__n_neighbors=7, SCL=MinMaxScaler();, score=-0.729 total time=   0.0s\n",
      "[CV 5/5] END KNN__n_neighbors=7, SCL=MinMaxScaler();, score=-0.714 total time=   0.1s\n",
      "[CV 1/5] END .....KNN__n_neighbors=8, SCL=None;, score=-0.737 total time=   0.0s\n",
      "[CV 2/5] END .....KNN__n_neighbors=8, SCL=None;, score=-0.744 total time=   0.0s\n",
      "[CV 3/5] END .....KNN__n_neighbors=8, SCL=None;, score=-0.737 total time=   0.0s\n",
      "[CV 4/5] END .....KNN__n_neighbors=8, SCL=None;, score=-0.763 total time=   0.0s\n",
      "[CV 5/5] END .....KNN__n_neighbors=8, SCL=None;, score=-0.737 total time=   0.0s\n",
      "[CV 1/5] END KNN__n_neighbors=8, SCL=StandardScaler();, score=-0.656 total time=   0.2s\n",
      "[CV 2/5] END KNN__n_neighbors=8, SCL=StandardScaler();, score=-0.750 total time=   0.1s\n",
      "[CV 3/5] END KNN__n_neighbors=8, SCL=StandardScaler();, score=-0.700 total time=   0.1s\n",
      "[CV 4/5] END KNN__n_neighbors=8, SCL=StandardScaler();, score=-0.712 total time=   0.2s\n",
      "[CV 5/5] END KNN__n_neighbors=8, SCL=StandardScaler();, score=-0.725 total time=   0.2s\n",
      "[CV 1/5] END KNN__n_neighbors=8, SCL=MinMaxScaler();, score=-0.700 total time=   0.1s\n",
      "[CV 2/5] END KNN__n_neighbors=8, SCL=MinMaxScaler();, score=-0.750 total time=   0.1s\n",
      "[CV 3/5] END KNN__n_neighbors=8, SCL=MinMaxScaler();, score=-0.725 total time=   0.1s\n",
      "[CV 4/5] END KNN__n_neighbors=8, SCL=MinMaxScaler();, score=-0.737 total time=   0.1s\n",
      "[CV 5/5] END KNN__n_neighbors=8, SCL=MinMaxScaler();, score=-0.713 total time=   0.1s\n",
      "[CV 1/5] END .....KNN__n_neighbors=9, SCL=None;, score=-0.744 total time=   0.0s\n",
      "[CV 2/5] END .....KNN__n_neighbors=9, SCL=None;, score=-0.756 total time=   0.0s\n",
      "[CV 3/5] END .....KNN__n_neighbors=9, SCL=None;, score=-0.733 total time=   0.0s\n",
      "[CV 4/5] END .....KNN__n_neighbors=9, SCL=None;, score=-0.767 total time=   0.0s\n",
      "[CV 5/5] END .....KNN__n_neighbors=9, SCL=None;, score=-0.733 total time=   0.0s\n",
      "[CV 1/5] END KNN__n_neighbors=9, SCL=StandardScaler();, score=-0.678 total time=   0.1s\n",
      "[CV 2/5] END KNN__n_neighbors=9, SCL=StandardScaler();, score=-0.739 total time=   0.2s\n",
      "[CV 3/5] END KNN__n_neighbors=9, SCL=StandardScaler();, score=-0.689 total time=   0.2s\n",
      "[CV 4/5] END KNN__n_neighbors=9, SCL=StandardScaler();, score=-0.700 total time=   0.2s\n",
      "[CV 5/5] END KNN__n_neighbors=9, SCL=StandardScaler();, score=-0.711 total time=   0.2s\n",
      "[CV 1/5] END KNN__n_neighbors=9, SCL=MinMaxScaler();, score=-0.689 total time=   0.1s\n",
      "[CV 2/5] END KNN__n_neighbors=9, SCL=MinMaxScaler();, score=-0.756 total time=   0.1s\n",
      "[CV 3/5] END KNN__n_neighbors=9, SCL=MinMaxScaler();, score=-0.733 total time=   0.1s\n",
      "[CV 4/5] END KNN__n_neighbors=9, SCL=MinMaxScaler();, score=-0.733 total time=   0.1s\n",
      "[CV 5/5] END KNN__n_neighbors=9, SCL=MinMaxScaler();, score=-0.711 total time=   0.1s\n",
      "[CV 1/5] END ....KNN__n_neighbors=10, SCL=None;, score=-0.757 total time=   0.0s\n",
      "[CV 2/5] END ....KNN__n_neighbors=10, SCL=None;, score=-0.760 total time=   0.0s\n",
      "[CV 3/5] END ....KNN__n_neighbors=10, SCL=None;, score=-0.750 total time=   0.0s\n",
      "[CV 4/5] END ....KNN__n_neighbors=10, SCL=None;, score=-0.760 total time=   0.0s\n",
      "[CV 5/5] END ....KNN__n_neighbors=10, SCL=None;, score=-0.740 total time=   0.0s\n",
      "[CV 1/5] END KNN__n_neighbors=10, SCL=StandardScaler();, score=-0.660 total time=   0.1s\n",
      "[CV 2/5] END KNN__n_neighbors=10, SCL=StandardScaler();, score=-0.740 total time=   0.2s\n",
      "[CV 3/5] END KNN__n_neighbors=10, SCL=StandardScaler();, score=-0.700 total time=   0.2s\n",
      "[CV 4/5] END KNN__n_neighbors=10, SCL=StandardScaler();, score=-0.700 total time=   0.1s\n",
      "[CV 5/5] END KNN__n_neighbors=10, SCL=StandardScaler();, score=-0.720 total time=   0.2s\n",
      "[CV 1/5] END KNN__n_neighbors=10, SCL=MinMaxScaler();, score=-0.680 total time=   0.1s\n",
      "[CV 2/5] END KNN__n_neighbors=10, SCL=MinMaxScaler();, score=-0.740 total time=   0.1s\n",
      "[CV 3/5] END KNN__n_neighbors=10, SCL=MinMaxScaler();, score=-0.740 total time=   0.1s\n",
      "[CV 4/5] END KNN__n_neighbors=10, SCL=MinMaxScaler();, score=-0.740 total time=   0.1s\n",
      "[CV 5/5] END KNN__n_neighbors=10, SCL=MinMaxScaler();, score=-0.730 total time=   0.1s\n",
      "[CV 1/5] END ....KNN__n_neighbors=11, SCL=None;, score=-0.745 total time=   0.0s\n",
      "[CV 2/5] END ....KNN__n_neighbors=11, SCL=None;, score=-0.764 total time=   0.0s\n",
      "[CV 3/5] END ....KNN__n_neighbors=11, SCL=None;, score=-0.745 total time=   0.0s\n",
      "[CV 4/5] END ....KNN__n_neighbors=11, SCL=None;, score=-0.755 total time=   0.0s\n",
      "[CV 5/5] END ....KNN__n_neighbors=11, SCL=None;, score=-0.745 total time=   0.0s\n",
      "[CV 1/5] END KNN__n_neighbors=11, SCL=StandardScaler();, score=-0.673 total time=   0.1s\n",
      "[CV 2/5] END KNN__n_neighbors=11, SCL=StandardScaler();, score=-0.727 total time=   0.1s\n",
      "[CV 3/5] END KNN__n_neighbors=11, SCL=StandardScaler();, score=-0.700 total time=   0.2s\n",
      "[CV 4/5] END KNN__n_neighbors=11, SCL=StandardScaler();, score=-0.727 total time=   0.2s\n",
      "[CV 5/5] END KNN__n_neighbors=11, SCL=StandardScaler();, score=-0.718 total time=   0.2s\n",
      "[CV 1/5] END KNN__n_neighbors=11, SCL=MinMaxScaler();, score=-0.691 total time=   0.1s\n",
      "[CV 2/5] END KNN__n_neighbors=11, SCL=MinMaxScaler();, score=-0.736 total time=   0.1s\n",
      "[CV 3/5] END KNN__n_neighbors=11, SCL=MinMaxScaler();, score=-0.745 total time=   0.1s\n",
      "[CV 4/5] END KNN__n_neighbors=11, SCL=MinMaxScaler();, score=-0.727 total time=   0.1s\n",
      "[CV 5/5] END KNN__n_neighbors=11, SCL=MinMaxScaler();, score=-0.727 total time=   0.1s\n",
      "[CV 1/5] END ....KNN__n_neighbors=12, SCL=None;, score=-0.742 total time=   0.0s\n",
      "[CV 2/5] END ....KNN__n_neighbors=12, SCL=None;, score=-0.775 total time=   0.0s\n",
      "[CV 3/5] END ....KNN__n_neighbors=12, SCL=None;, score=-0.750 total time=   0.0s\n",
      "[CV 4/5] END ....KNN__n_neighbors=12, SCL=None;, score=-0.758 total time=   0.0s\n",
      "[CV 5/5] END ....KNN__n_neighbors=12, SCL=None;, score=-0.742 total time=   0.0s\n",
      "[CV 1/5] END KNN__n_neighbors=12, SCL=StandardScaler();, score=-0.675 total time=   0.1s\n",
      "[CV 2/5] END KNN__n_neighbors=12, SCL=StandardScaler();, score=-0.725 total time=   0.2s\n",
      "[CV 3/5] END KNN__n_neighbors=12, SCL=StandardScaler();, score=-0.708 total time=   0.2s\n",
      "[CV 4/5] END KNN__n_neighbors=12, SCL=StandardScaler();, score=-0.725 total time=   0.2s\n",
      "[CV 5/5] END KNN__n_neighbors=12, SCL=StandardScaler();, score=-0.708 total time=   0.2s\n",
      "[CV 1/5] END KNN__n_neighbors=12, SCL=MinMaxScaler();, score=-0.700 total time=   0.1s\n",
      "[CV 2/5] END KNN__n_neighbors=12, SCL=MinMaxScaler();, score=-0.725 total time=   0.1s\n",
      "[CV 3/5] END KNN__n_neighbors=12, SCL=MinMaxScaler();, score=-0.742 total time=   0.1s\n",
      "[CV 4/5] END KNN__n_neighbors=12, SCL=MinMaxScaler();, score=-0.750 total time=   0.1s\n",
      "[CV 5/5] END KNN__n_neighbors=12, SCL=MinMaxScaler();, score=-0.725 total time=   0.1s\n",
      "[CV 1/5] END ....KNN__n_neighbors=13, SCL=None;, score=-0.754 total time=   0.0s\n",
      "[CV 2/5] END ....KNN__n_neighbors=13, SCL=None;, score=-0.769 total time=   0.0s\n",
      "[CV 3/5] END ....KNN__n_neighbors=13, SCL=None;, score=-0.738 total time=   0.0s\n",
      "[CV 4/5] END ....KNN__n_neighbors=13, SCL=None;, score=-0.769 total time=   0.0s\n",
      "[CV 5/5] END ....KNN__n_neighbors=13, SCL=None;, score=-0.746 total time=   0.0s\n",
      "[CV 1/5] END KNN__n_neighbors=13, SCL=StandardScaler();, score=-0.681 total time=   0.2s\n",
      "[CV 2/5] END KNN__n_neighbors=13, SCL=StandardScaler();, score=-0.723 total time=   0.2s\n",
      "[CV 3/5] END KNN__n_neighbors=13, SCL=StandardScaler();, score=-0.708 total time=   0.2s\n",
      "[CV 4/5] END KNN__n_neighbors=13, SCL=StandardScaler();, score=-0.723 total time=   0.2s\n",
      "[CV 5/5] END KNN__n_neighbors=13, SCL=StandardScaler();, score=-0.715 total time=   0.2s\n",
      "[CV 1/5] END KNN__n_neighbors=13, SCL=MinMaxScaler();, score=-0.700 total time=   0.2s\n",
      "[CV 2/5] END KNN__n_neighbors=13, SCL=MinMaxScaler();, score=-0.731 total time=   0.1s\n",
      "[CV 3/5] END KNN__n_neighbors=13, SCL=MinMaxScaler();, score=-0.731 total time=   0.2s\n",
      "[CV 4/5] END KNN__n_neighbors=13, SCL=MinMaxScaler();, score=-0.746 total time=   0.1s\n",
      "[CV 5/5] END KNN__n_neighbors=13, SCL=MinMaxScaler();, score=-0.723 total time=   0.1s\n",
      "[CV 1/5] END ....KNN__n_neighbors=14, SCL=None;, score=-0.743 total time=   0.0s\n",
      "[CV 2/5] END ....KNN__n_neighbors=14, SCL=None;, score=-0.784 total time=   0.0s\n",
      "[CV 3/5] END ....KNN__n_neighbors=14, SCL=None;, score=-0.729 total time=   0.0s\n",
      "[CV 4/5] END ....KNN__n_neighbors=14, SCL=None;, score=-0.764 total time=   0.0s\n",
      "[CV 5/5] END ....KNN__n_neighbors=14, SCL=None;, score=-0.757 total time=   0.0s\n",
      "[CV 1/5] END KNN__n_neighbors=14, SCL=StandardScaler();, score=-0.671 total time=   0.2s\n",
      "[CV 2/5] END KNN__n_neighbors=14, SCL=StandardScaler();, score=-0.721 total time=   0.2s\n",
      "[CV 3/5] END KNN__n_neighbors=14, SCL=StandardScaler();, score=-0.707 total time=   0.2s\n",
      "[CV 4/5] END KNN__n_neighbors=14, SCL=StandardScaler();, score=-0.714 total time=   0.2s\n",
      "[CV 5/5] END KNN__n_neighbors=14, SCL=StandardScaler();, score=-0.707 total time=   0.2s\n",
      "[CV 1/5] END KNN__n_neighbors=14, SCL=MinMaxScaler();, score=-0.700 total time=   0.1s\n",
      "[CV 2/5] END KNN__n_neighbors=14, SCL=MinMaxScaler();, score=-0.739 total time=   0.1s\n",
      "[CV 3/5] END KNN__n_neighbors=14, SCL=MinMaxScaler();, score=-0.721 total time=   0.1s\n",
      "[CV 4/5] END KNN__n_neighbors=14, SCL=MinMaxScaler();, score=-0.736 total time=   0.1s\n",
      "[CV 5/5] END KNN__n_neighbors=14, SCL=MinMaxScaler();, score=-0.736 total time=   0.1s\n",
      "[CV 1/5] END ....KNN__n_neighbors=15, SCL=None;, score=-0.760 total time=   0.0s\n",
      "[CV 2/5] END ....KNN__n_neighbors=15, SCL=None;, score=-0.797 total time=   0.0s\n",
      "[CV 3/5] END ....KNN__n_neighbors=15, SCL=None;, score=-0.720 total time=   0.0s\n",
      "[CV 4/5] END ....KNN__n_neighbors=15, SCL=None;, score=-0.787 total time=   0.0s\n",
      "[CV 5/5] END ....KNN__n_neighbors=15, SCL=None;, score=-0.753 total time=   0.0s\n",
      "[CV 1/5] END KNN__n_neighbors=15, SCL=StandardScaler();, score=-0.673 total time=   0.2s\n",
      "[CV 2/5] END KNN__n_neighbors=15, SCL=StandardScaler();, score=-0.713 total time=   0.2s\n",
      "[CV 3/5] END KNN__n_neighbors=15, SCL=StandardScaler();, score=-0.700 total time=   0.2s\n",
      "[CV 4/5] END KNN__n_neighbors=15, SCL=StandardScaler();, score=-0.720 total time=   0.2s\n",
      "[CV 5/5] END KNN__n_neighbors=15, SCL=StandardScaler();, score=-0.700 total time=   0.2s\n",
      "[CV 1/5] END KNN__n_neighbors=15, SCL=MinMaxScaler();, score=-0.700 total time=   0.1s\n",
      "[CV 2/5] END KNN__n_neighbors=15, SCL=MinMaxScaler();, score=-0.737 total time=   0.1s\n",
      "[CV 3/5] END KNN__n_neighbors=15, SCL=MinMaxScaler();, score=-0.727 total time=   0.1s\n",
      "[CV 4/5] END KNN__n_neighbors=15, SCL=MinMaxScaler();, score=-0.753 total time=   0.1s\n",
      "[CV 5/5] END KNN__n_neighbors=15, SCL=MinMaxScaler();, score=-0.727 total time=   0.1s\n",
      "[CV 1/5] END ....KNN__n_neighbors=16, SCL=None;, score=-0.756 total time=   0.0s\n",
      "[CV 2/5] END ....KNN__n_neighbors=16, SCL=None;, score=-0.794 total time=   0.0s\n",
      "[CV 3/5] END ....KNN__n_neighbors=16, SCL=None;, score=-0.706 total time=   0.0s\n",
      "[CV 4/5] END ....KNN__n_neighbors=16, SCL=None;, score=-0.787 total time=   0.0s\n",
      "[CV 5/5] END ....KNN__n_neighbors=16, SCL=None;, score=-0.763 total time=   0.0s\n",
      "[CV 1/5] END KNN__n_neighbors=16, SCL=StandardScaler();, score=-0.675 total time=   0.2s\n",
      "[CV 2/5] END KNN__n_neighbors=16, SCL=StandardScaler();, score=-0.719 total time=   0.2s\n",
      "[CV 3/5] END KNN__n_neighbors=16, SCL=StandardScaler();, score=-0.700 total time=   0.2s\n",
      "[CV 4/5] END KNN__n_neighbors=16, SCL=StandardScaler();, score=-0.731 total time=   0.2s\n",
      "[CV 5/5] END KNN__n_neighbors=16, SCL=StandardScaler();, score=-0.700 total time=   0.2s\n",
      "[CV 1/5] END KNN__n_neighbors=16, SCL=MinMaxScaler();, score=-0.700 total time=   0.1s\n",
      "[CV 2/5] END KNN__n_neighbors=16, SCL=MinMaxScaler();, score=-0.744 total time=   0.1s\n",
      "[CV 3/5] END KNN__n_neighbors=16, SCL=MinMaxScaler();, score=-0.731 total time=   0.1s\n",
      "[CV 4/5] END KNN__n_neighbors=16, SCL=MinMaxScaler();, score=-0.750 total time=   0.1s\n",
      "[CV 5/5] END KNN__n_neighbors=16, SCL=MinMaxScaler();, score=-0.713 total time=   0.1s\n",
      "[CV 1/5] END ....KNN__n_neighbors=17, SCL=None;, score=-0.753 total time=   0.0s\n",
      "[CV 2/5] END ....KNN__n_neighbors=17, SCL=None;, score=-0.788 total time=   0.0s\n",
      "[CV 3/5] END ....KNN__n_neighbors=17, SCL=None;, score=-0.712 total time=   0.0s\n",
      "[CV 4/5] END ....KNN__n_neighbors=17, SCL=None;, score=-0.800 total time=   0.0s\n",
      "[CV 5/5] END ....KNN__n_neighbors=17, SCL=None;, score=-0.776 total time=   0.0s\n",
      "[CV 1/5] END KNN__n_neighbors=17, SCL=StandardScaler();, score=-0.674 total time=   0.2s\n",
      "[CV 2/5] END KNN__n_neighbors=17, SCL=StandardScaler();, score=-0.706 total time=   0.2s\n",
      "[CV 3/5] END KNN__n_neighbors=17, SCL=StandardScaler();, score=-0.688 total time=   0.2s\n",
      "[CV 4/5] END KNN__n_neighbors=17, SCL=StandardScaler();, score=-0.729 total time=   0.3s\n",
      "[CV 5/5] END KNN__n_neighbors=17, SCL=StandardScaler();, score=-0.688 total time=   0.2s\n",
      "[CV 1/5] END KNN__n_neighbors=17, SCL=MinMaxScaler();, score=-0.706 total time=   0.1s\n",
      "[CV 2/5] END KNN__n_neighbors=17, SCL=MinMaxScaler();, score=-0.735 total time=   0.1s\n",
      "[CV 3/5] END KNN__n_neighbors=17, SCL=MinMaxScaler();, score=-0.729 total time=   0.1s\n",
      "[CV 4/5] END KNN__n_neighbors=17, SCL=MinMaxScaler();, score=-0.753 total time=   0.1s\n",
      "[CV 5/5] END KNN__n_neighbors=17, SCL=MinMaxScaler();, score=-0.718 total time=   0.1s\n",
      "[CV 1/5] END ....KNN__n_neighbors=18, SCL=None;, score=-0.758 total time=   0.0s\n",
      "[CV 2/5] END ....KNN__n_neighbors=18, SCL=None;, score=-0.792 total time=   0.0s\n",
      "[CV 3/5] END ....KNN__n_neighbors=18, SCL=None;, score=-0.711 total time=   0.0s\n",
      "[CV 4/5] END ....KNN__n_neighbors=18, SCL=None;, score=-0.800 total time=   0.0s\n",
      "[CV 5/5] END ....KNN__n_neighbors=18, SCL=None;, score=-0.761 total time=   0.0s\n",
      "[CV 1/5] END KNN__n_neighbors=18, SCL=StandardScaler();, score=-0.683 total time=   0.2s\n",
      "[CV 2/5] END KNN__n_neighbors=18, SCL=StandardScaler();, score=-0.717 total time=   0.2s\n",
      "[CV 3/5] END KNN__n_neighbors=18, SCL=StandardScaler();, score=-0.706 total time=   0.2s\n",
      "[CV 4/5] END KNN__n_neighbors=18, SCL=StandardScaler();, score=-0.728 total time=   0.2s\n",
      "[CV 5/5] END KNN__n_neighbors=18, SCL=StandardScaler();, score=-0.700 total time=   0.2s\n",
      "[CV 1/5] END KNN__n_neighbors=18, SCL=MinMaxScaler();, score=-0.697 total time=   0.1s\n",
      "[CV 2/5] END KNN__n_neighbors=18, SCL=MinMaxScaler();, score=-0.733 total time=   0.1s\n",
      "[CV 3/5] END KNN__n_neighbors=18, SCL=MinMaxScaler();, score=-0.733 total time=   0.1s\n",
      "[CV 4/5] END KNN__n_neighbors=18, SCL=MinMaxScaler();, score=-0.750 total time=   0.1s\n",
      "[CV 5/5] END KNN__n_neighbors=18, SCL=MinMaxScaler();, score=-0.717 total time=   0.2s\n",
      "[CV 1/5] END ....KNN__n_neighbors=19, SCL=None;, score=-0.758 total time=   0.0s\n",
      "[CV 2/5] END ....KNN__n_neighbors=19, SCL=None;, score=-0.789 total time=   0.0s\n",
      "[CV 3/5] END ....KNN__n_neighbors=19, SCL=None;, score=-0.721 total time=   0.0s\n",
      "[CV 4/5] END ....KNN__n_neighbors=19, SCL=None;, score=-0.805 total time=   0.0s\n",
      "[CV 5/5] END ....KNN__n_neighbors=19, SCL=None;, score=-0.753 total time=   0.0s\n",
      "[CV 1/5] END KNN__n_neighbors=19, SCL=StandardScaler();, score=-0.674 total time=   0.2s\n",
      "[CV 2/5] END KNN__n_neighbors=19, SCL=StandardScaler();, score=-0.711 total time=   0.2s\n",
      "[CV 3/5] END KNN__n_neighbors=19, SCL=StandardScaler();, score=-0.711 total time=   0.2s\n",
      "[CV 4/5] END KNN__n_neighbors=19, SCL=StandardScaler();, score=-0.726 total time=   0.2s\n",
      "[CV 5/5] END KNN__n_neighbors=19, SCL=StandardScaler();, score=-0.695 total time=   0.2s\n",
      "[CV 1/5] END KNN__n_neighbors=19, SCL=MinMaxScaler();, score=-0.689 total time=   0.1s\n",
      "[CV 2/5] END KNN__n_neighbors=19, SCL=MinMaxScaler();, score=-0.737 total time=   0.1s\n",
      "[CV 3/5] END KNN__n_neighbors=19, SCL=MinMaxScaler();, score=-0.726 total time=   0.1s\n",
      "[CV 4/5] END KNN__n_neighbors=19, SCL=MinMaxScaler();, score=-0.758 total time=   0.1s\n",
      "[CV 5/5] END KNN__n_neighbors=19, SCL=MinMaxScaler();, score=-0.726 total time=   0.1s\n",
      "[CV 1/5] END ....KNN__n_neighbors=20, SCL=None;, score=-0.755 total time=   0.0s\n",
      "[CV 2/5] END ....KNN__n_neighbors=20, SCL=None;, score=-0.800 total time=   0.0s\n",
      "[CV 3/5] END ....KNN__n_neighbors=20, SCL=None;, score=-0.730 total time=   0.0s\n",
      "[CV 4/5] END ....KNN__n_neighbors=20, SCL=None;, score=-0.810 total time=   0.0s\n",
      "[CV 5/5] END ....KNN__n_neighbors=20, SCL=None;, score=-0.760 total time=   0.0s\n",
      "[CV 1/5] END KNN__n_neighbors=20, SCL=StandardScaler();, score=-0.667 total time=   0.2s\n",
      "[CV 2/5] END KNN__n_neighbors=20, SCL=StandardScaler();, score=-0.708 total time=   0.2s\n",
      "[CV 3/5] END KNN__n_neighbors=20, SCL=StandardScaler();, score=-0.705 total time=   0.2s\n",
      "[CV 4/5] END KNN__n_neighbors=20, SCL=StandardScaler();, score=-0.720 total time=   0.2s\n",
      "[CV 5/5] END KNN__n_neighbors=20, SCL=StandardScaler();, score=-0.695 total time=   0.2s\n",
      "[CV 1/5] END KNN__n_neighbors=20, SCL=MinMaxScaler();, score=-0.695 total time=   0.1s\n",
      "[CV 2/5] END KNN__n_neighbors=20, SCL=MinMaxScaler();, score=-0.735 total time=   0.1s\n",
      "[CV 3/5] END KNN__n_neighbors=20, SCL=MinMaxScaler();, score=-0.750 total time=   0.1s\n",
      "[CV 4/5] END KNN__n_neighbors=20, SCL=MinMaxScaler();, score=-0.750 total time=   0.2s\n",
      "[CV 5/5] END KNN__n_neighbors=20, SCL=MinMaxScaler();, score=-0.720 total time=   0.1s\n",
      "[CV 1/5] END ....KNN__n_neighbors=21, SCL=None;, score=-0.767 total time=   0.0s\n",
      "[CV 2/5] END ....KNN__n_neighbors=21, SCL=None;, score=-0.795 total time=   0.0s\n",
      "[CV 3/5] END ....KNN__n_neighbors=21, SCL=None;, score=-0.738 total time=   0.0s\n",
      "[CV 4/5] END ....KNN__n_neighbors=21, SCL=None;, score=-0.800 total time=   0.0s\n",
      "[CV 5/5] END ....KNN__n_neighbors=21, SCL=None;, score=-0.757 total time=   0.0s\n",
      "[CV 1/5] END KNN__n_neighbors=21, SCL=StandardScaler();, score=-0.676 total time=   0.2s\n",
      "[CV 2/5] END KNN__n_neighbors=21, SCL=StandardScaler();, score=-0.705 total time=   0.2s\n",
      "[CV 3/5] END KNN__n_neighbors=21, SCL=StandardScaler();, score=-0.714 total time=   0.2s\n",
      "[CV 4/5] END KNN__n_neighbors=21, SCL=StandardScaler();, score=-0.719 total time=   0.2s\n",
      "[CV 5/5] END KNN__n_neighbors=21, SCL=StandardScaler();, score=-0.690 total time=   0.2s\n",
      "[CV 1/5] END KNN__n_neighbors=21, SCL=MinMaxScaler();, score=-0.690 total time=   0.1s\n",
      "[CV 2/5] END KNN__n_neighbors=21, SCL=MinMaxScaler();, score=-0.738 total time=   0.1s\n",
      "[CV 3/5] END KNN__n_neighbors=21, SCL=MinMaxScaler();, score=-0.738 total time=   0.2s\n",
      "[CV 4/5] END KNN__n_neighbors=21, SCL=MinMaxScaler();, score=-0.743 total time=   0.1s\n",
      "[CV 5/5] END KNN__n_neighbors=21, SCL=MinMaxScaler();, score=-0.719 total time=   0.1s\n",
      "[CV 1/5] END ....KNN__n_neighbors=22, SCL=None;, score=-0.764 total time=   0.0s\n",
      "[CV 2/5] END ....KNN__n_neighbors=22, SCL=None;, score=-0.814 total time=   0.0s\n",
      "[CV 3/5] END ....KNN__n_neighbors=22, SCL=None;, score=-0.736 total time=   0.0s\n",
      "[CV 4/5] END ....KNN__n_neighbors=22, SCL=None;, score=-0.805 total time=   0.0s\n",
      "[CV 5/5] END ....KNN__n_neighbors=22, SCL=None;, score=-0.764 total time=   0.0s\n",
      "[CV 1/5] END KNN__n_neighbors=22, SCL=StandardScaler();, score=-0.673 total time=   0.2s\n",
      "[CV 2/5] END KNN__n_neighbors=22, SCL=StandardScaler();, score=-0.689 total time=   0.2s\n",
      "[CV 3/5] END KNN__n_neighbors=22, SCL=StandardScaler();, score=-0.709 total time=   0.2s\n",
      "[CV 4/5] END KNN__n_neighbors=22, SCL=StandardScaler();, score=-0.727 total time=   0.3s\n",
      "[CV 5/5] END KNN__n_neighbors=22, SCL=StandardScaler();, score=-0.677 total time=   0.2s\n",
      "[CV 1/5] END KNN__n_neighbors=22, SCL=MinMaxScaler();, score=-0.705 total time=   0.1s\n",
      "[CV 2/5] END KNN__n_neighbors=22, SCL=MinMaxScaler();, score=-0.750 total time=   0.1s\n",
      "[CV 3/5] END KNN__n_neighbors=22, SCL=MinMaxScaler();, score=-0.736 total time=   0.1s\n",
      "[CV 4/5] END KNN__n_neighbors=22, SCL=MinMaxScaler();, score=-0.745 total time=   0.2s\n",
      "[CV 5/5] END KNN__n_neighbors=22, SCL=MinMaxScaler();, score=-0.714 total time=   0.1s\n",
      "[CV 1/5] END ....KNN__n_neighbors=23, SCL=None;, score=-0.761 total time=   0.0s\n",
      "[CV 2/5] END ....KNN__n_neighbors=23, SCL=None;, score=-0.809 total time=   0.0s\n",
      "[CV 3/5] END ....KNN__n_neighbors=23, SCL=None;, score=-0.730 total time=   0.0s\n",
      "[CV 4/5] END ....KNN__n_neighbors=23, SCL=None;, score=-0.822 total time=   0.0s\n",
      "[CV 5/5] END ....KNN__n_neighbors=23, SCL=None;, score=-0.770 total time=   0.0s\n",
      "[CV 1/5] END KNN__n_neighbors=23, SCL=StandardScaler();, score=-0.674 total time=   0.2s\n",
      "[CV 2/5] END KNN__n_neighbors=23, SCL=StandardScaler();, score=-0.711 total time=   0.2s\n",
      "[CV 3/5] END KNN__n_neighbors=23, SCL=StandardScaler();, score=-0.709 total time=   0.2s\n",
      "[CV 4/5] END KNN__n_neighbors=23, SCL=StandardScaler();, score=-0.726 total time=   0.2s\n",
      "[CV 5/5] END KNN__n_neighbors=23, SCL=StandardScaler();, score=-0.674 total time=   0.2s\n",
      "[CV 1/5] END KNN__n_neighbors=23, SCL=MinMaxScaler();, score=-0.709 total time=   0.2s\n",
      "[CV 2/5] END KNN__n_neighbors=23, SCL=MinMaxScaler();, score=-0.743 total time=   0.1s\n",
      "[CV 3/5] END KNN__n_neighbors=23, SCL=MinMaxScaler();, score=-0.735 total time=   0.2s\n",
      "[CV 4/5] END KNN__n_neighbors=23, SCL=MinMaxScaler();, score=-0.739 total time=   0.2s\n",
      "[CV 5/5] END KNN__n_neighbors=23, SCL=MinMaxScaler();, score=-0.717 total time=   0.2s\n",
      "[CV 1/5] END ....KNN__n_neighbors=24, SCL=None;, score=-0.775 total time=   0.0s\n",
      "[CV 2/5] END ....KNN__n_neighbors=24, SCL=None;, score=-0.800 total time=   0.0s\n",
      "[CV 3/5] END ....KNN__n_neighbors=24, SCL=None;, score=-0.742 total time=   0.0s\n",
      "[CV 4/5] END ....KNN__n_neighbors=24, SCL=None;, score=-0.819 total time=   0.0s\n",
      "[CV 5/5] END ....KNN__n_neighbors=24, SCL=None;, score=-0.771 total time=   0.0s\n",
      "[CV 1/5] END KNN__n_neighbors=24, SCL=StandardScaler();, score=-0.679 total time=   0.2s\n",
      "[CV 2/5] END KNN__n_neighbors=24, SCL=StandardScaler();, score=-0.717 total time=   0.3s\n",
      "[CV 3/5] END KNN__n_neighbors=24, SCL=StandardScaler();, score=-0.708 total time=   0.3s\n",
      "[CV 4/5] END KNN__n_neighbors=24, SCL=StandardScaler();, score=-0.738 total time=   0.2s\n",
      "[CV 5/5] END KNN__n_neighbors=24, SCL=StandardScaler();, score=-0.679 total time=   0.2s\n",
      "[CV 1/5] END KNN__n_neighbors=24, SCL=MinMaxScaler();, score=-0.698 total time=   0.1s\n",
      "[CV 2/5] END KNN__n_neighbors=24, SCL=MinMaxScaler();, score=-0.738 total time=   0.1s\n",
      "[CV 3/5] END KNN__n_neighbors=24, SCL=MinMaxScaler();, score=-0.729 total time=   0.1s\n",
      "[CV 4/5] END KNN__n_neighbors=24, SCL=MinMaxScaler();, score=-0.758 total time=   0.1s\n",
      "[CV 5/5] END KNN__n_neighbors=24, SCL=MinMaxScaler();, score=-0.712 total time=   0.1s\n",
      "[CV 1/5] END ....KNN__n_neighbors=25, SCL=None;, score=-0.766 total time=   0.0s\n",
      "[CV 2/5] END ....KNN__n_neighbors=25, SCL=None;, score=-0.808 total time=   0.0s\n",
      "[CV 3/5] END ....KNN__n_neighbors=25, SCL=None;, score=-0.752 total time=   0.0s\n",
      "[CV 4/5] END ....KNN__n_neighbors=25, SCL=None;, score=-0.816 total time=   0.0s\n",
      "[CV 5/5] END ....KNN__n_neighbors=25, SCL=None;, score=-0.780 total time=   0.0s\n",
      "[CV 1/5] END KNN__n_neighbors=25, SCL=StandardScaler();, score=-0.674 total time=   0.3s\n",
      "[CV 2/5] END KNN__n_neighbors=25, SCL=StandardScaler();, score=-0.708 total time=   0.2s\n",
      "[CV 3/5] END KNN__n_neighbors=25, SCL=StandardScaler();, score=-0.712 total time=   0.2s\n",
      "[CV 4/5] END KNN__n_neighbors=25, SCL=StandardScaler();, score=-0.736 total time=   0.2s\n",
      "[CV 5/5] END KNN__n_neighbors=25, SCL=StandardScaler();, score=-0.676 total time=   0.2s\n",
      "[CV 1/5] END KNN__n_neighbors=25, SCL=MinMaxScaler();, score=-0.700 total time=   0.1s\n",
      "[CV 2/5] END KNN__n_neighbors=25, SCL=MinMaxScaler();, score=-0.744 total time=   0.1s\n",
      "[CV 3/5] END KNN__n_neighbors=25, SCL=MinMaxScaler();, score=-0.736 total time=   0.1s\n",
      "[CV 4/5] END KNN__n_neighbors=25, SCL=MinMaxScaler();, score=-0.752 total time=   0.1s\n",
      "[CV 5/5] END KNN__n_neighbors=25, SCL=MinMaxScaler();, score=-0.716 total time=   0.1s\n",
      "[CV 1/5] END ....KNN__n_neighbors=26, SCL=None;, score=-0.765 total time=   0.0s\n",
      "[CV 2/5] END ....KNN__n_neighbors=26, SCL=None;, score=-0.812 total time=   0.0s\n",
      "[CV 3/5] END ....KNN__n_neighbors=26, SCL=None;, score=-0.754 total time=   0.0s\n",
      "[CV 4/5] END ....KNN__n_neighbors=26, SCL=None;, score=-0.815 total time=   0.0s\n",
      "[CV 5/5] END ....KNN__n_neighbors=26, SCL=None;, score=-0.773 total time=   0.0s\n",
      "[CV 1/5] END KNN__n_neighbors=26, SCL=StandardScaler();, score=-0.683 total time=   0.3s\n",
      "[CV 2/5] END KNN__n_neighbors=26, SCL=StandardScaler();, score=-0.715 total time=   0.2s\n",
      "[CV 3/5] END KNN__n_neighbors=26, SCL=StandardScaler();, score=-0.715 total time=   0.3s\n",
      "[CV 4/5] END KNN__n_neighbors=26, SCL=StandardScaler();, score=-0.742 total time=   0.2s\n",
      "[CV 5/5] END KNN__n_neighbors=26, SCL=StandardScaler();, score=-0.688 total time=   0.2s\n",
      "[CV 1/5] END KNN__n_neighbors=26, SCL=MinMaxScaler();, score=-0.696 total time=   0.1s\n",
      "[CV 2/5] END KNN__n_neighbors=26, SCL=MinMaxScaler();, score=-0.746 total time=   0.1s\n",
      "[CV 3/5] END KNN__n_neighbors=26, SCL=MinMaxScaler();, score=-0.727 total time=   0.2s\n",
      "[CV 4/5] END KNN__n_neighbors=26, SCL=MinMaxScaler();, score=-0.746 total time=   0.2s\n",
      "[CV 5/5] END KNN__n_neighbors=26, SCL=MinMaxScaler();, score=-0.715 total time=   0.1s\n",
      "[CV 1/5] END ....KNN__n_neighbors=27, SCL=None;, score=-0.772 total time=   0.0s\n",
      "[CV 2/5] END ....KNN__n_neighbors=27, SCL=None;, score=-0.816 total time=   0.0s\n",
      "[CV 3/5] END ....KNN__n_neighbors=27, SCL=None;, score=-0.748 total time=   0.0s\n",
      "[CV 4/5] END ....KNN__n_neighbors=27, SCL=None;, score=-0.811 total time=   0.0s\n",
      "[CV 5/5] END ....KNN__n_neighbors=27, SCL=None;, score=-0.789 total time=   0.0s\n",
      "[CV 1/5] END KNN__n_neighbors=27, SCL=StandardScaler();, score=-0.678 total time=   0.2s\n",
      "[CV 2/5] END KNN__n_neighbors=27, SCL=StandardScaler();, score=-0.715 total time=   0.2s\n",
      "[CV 3/5] END KNN__n_neighbors=27, SCL=StandardScaler();, score=-0.711 total time=   0.2s\n",
      "[CV 4/5] END KNN__n_neighbors=27, SCL=StandardScaler();, score=-0.737 total time=   0.2s\n",
      "[CV 5/5] END KNN__n_neighbors=27, SCL=StandardScaler();, score=-0.689 total time=   0.3s\n",
      "[CV 1/5] END KNN__n_neighbors=27, SCL=MinMaxScaler();, score=-0.696 total time=   0.2s\n",
      "[CV 2/5] END KNN__n_neighbors=27, SCL=MinMaxScaler();, score=-0.743 total time=   0.2s\n",
      "[CV 3/5] END KNN__n_neighbors=27, SCL=MinMaxScaler();, score=-0.719 total time=   0.2s\n",
      "[CV 4/5] END KNN__n_neighbors=27, SCL=MinMaxScaler();, score=-0.756 total time=   0.1s\n",
      "[CV 5/5] END KNN__n_neighbors=27, SCL=MinMaxScaler();, score=-0.719 total time=   0.1s\n",
      "[CV 1/5] END ....KNN__n_neighbors=28, SCL=None;, score=-0.773 total time=   0.0s\n",
      "[CV 2/5] END ....KNN__n_neighbors=28, SCL=None;, score=-0.818 total time=   0.0s\n",
      "[CV 3/5] END ....KNN__n_neighbors=28, SCL=None;, score=-0.764 total time=   0.0s\n",
      "[CV 4/5] END ....KNN__n_neighbors=28, SCL=None;, score=-0.811 total time=   0.0s\n",
      "[CV 5/5] END ....KNN__n_neighbors=28, SCL=None;, score=-0.782 total time=   0.0s\n",
      "[CV 1/5] END KNN__n_neighbors=28, SCL=StandardScaler();, score=-0.680 total time=   0.2s\n",
      "[CV 2/5] END KNN__n_neighbors=28, SCL=StandardScaler();, score=-0.727 total time=   0.2s\n",
      "[CV 3/5] END KNN__n_neighbors=28, SCL=StandardScaler();, score=-0.725 total time=   0.2s\n",
      "[CV 4/5] END KNN__n_neighbors=28, SCL=StandardScaler();, score=-0.743 total time=   0.2s\n",
      "[CV 5/5] END KNN__n_neighbors=28, SCL=StandardScaler();, score=-0.686 total time=   0.2s\n",
      "[CV 1/5] END KNN__n_neighbors=28, SCL=MinMaxScaler();, score=-0.696 total time=   0.2s\n",
      "[CV 2/5] END KNN__n_neighbors=28, SCL=MinMaxScaler();, score=-0.739 total time=   0.2s\n",
      "[CV 3/5] END KNN__n_neighbors=28, SCL=MinMaxScaler();, score=-0.718 total time=   0.1s\n",
      "[CV 4/5] END KNN__n_neighbors=28, SCL=MinMaxScaler();, score=-0.757 total time=   0.1s\n",
      "[CV 5/5] END KNN__n_neighbors=28, SCL=MinMaxScaler();, score=-0.718 total time=   0.2s\n",
      "[CV 1/5] END ....KNN__n_neighbors=29, SCL=None;, score=-0.772 total time=   0.0s\n",
      "[CV 2/5] END ....KNN__n_neighbors=29, SCL=None;, score=-0.828 total time=   0.0s\n",
      "[CV 3/5] END ....KNN__n_neighbors=29, SCL=None;, score=-0.762 total time=   0.0s\n",
      "[CV 4/5] END ....KNN__n_neighbors=29, SCL=None;, score=-0.814 total time=   0.0s\n",
      "[CV 5/5] END ....KNN__n_neighbors=29, SCL=None;, score=-0.776 total time=   0.0s\n",
      "[CV 1/5] END KNN__n_neighbors=29, SCL=StandardScaler();, score=-0.672 total time=   0.2s\n",
      "[CV 2/5] END KNN__n_neighbors=29, SCL=StandardScaler();, score=-0.733 total time=   0.2s\n",
      "[CV 3/5] END KNN__n_neighbors=29, SCL=StandardScaler();, score=-0.731 total time=   0.3s\n",
      "[CV 4/5] END KNN__n_neighbors=29, SCL=StandardScaler();, score=-0.745 total time=   0.2s\n",
      "[CV 5/5] END KNN__n_neighbors=29, SCL=StandardScaler();, score=-0.686 total time=   0.2s\n",
      "[CV 1/5] END KNN__n_neighbors=29, SCL=MinMaxScaler();, score=-0.693 total time=   0.2s\n",
      "[CV 2/5] END KNN__n_neighbors=29, SCL=MinMaxScaler();, score=-0.729 total time=   0.1s\n",
      "[CV 3/5] END KNN__n_neighbors=29, SCL=MinMaxScaler();, score=-0.721 total time=   0.2s\n",
      "[CV 4/5] END KNN__n_neighbors=29, SCL=MinMaxScaler();, score=-0.759 total time=   0.2s\n",
      "[CV 5/5] END KNN__n_neighbors=29, SCL=MinMaxScaler();, score=-0.728 total time=   0.1s\n",
      "[CV 1/5] END ....KNN__n_neighbors=30, SCL=None;, score=-0.772 total time=   0.0s\n",
      "[CV 2/5] END ....KNN__n_neighbors=30, SCL=None;, score=-0.830 total time=   0.0s\n",
      "[CV 3/5] END ....KNN__n_neighbors=30, SCL=None;, score=-0.767 total time=   0.0s\n",
      "[CV 4/5] END ....KNN__n_neighbors=30, SCL=None;, score=-0.817 total time=   0.0s\n",
      "[CV 5/5] END ....KNN__n_neighbors=30, SCL=None;, score=-0.770 total time=   0.0s\n",
      "[CV 1/5] END KNN__n_neighbors=30, SCL=StandardScaler();, score=-0.672 total time=   0.2s\n",
      "[CV 2/5] END KNN__n_neighbors=30, SCL=StandardScaler();, score=-0.727 total time=   0.2s\n",
      "[CV 3/5] END KNN__n_neighbors=30, SCL=StandardScaler();, score=-0.723 total time=   0.3s\n",
      "[CV 4/5] END KNN__n_neighbors=30, SCL=StandardScaler();, score=-0.747 total time=   0.2s\n",
      "[CV 5/5] END KNN__n_neighbors=30, SCL=StandardScaler();, score=-0.690 total time=   0.2s\n",
      "[CV 1/5] END KNN__n_neighbors=30, SCL=MinMaxScaler();, score=-0.690 total time=   0.1s\n",
      "[CV 2/5] END KNN__n_neighbors=30, SCL=MinMaxScaler();, score=-0.738 total time=   0.2s\n",
      "[CV 3/5] END KNN__n_neighbors=30, SCL=MinMaxScaler();, score=-0.727 total time=   0.2s\n",
      "[CV 4/5] END KNN__n_neighbors=30, SCL=MinMaxScaler();, score=-0.758 total time=   0.2s\n",
      "[CV 5/5] END KNN__n_neighbors=30, SCL=MinMaxScaler();, score=-0.723 total time=   0.1s\n",
      "[CV 1/5] END ....KNN__n_neighbors=31, SCL=None;, score=-0.768 total time=   0.0s\n",
      "[CV 2/5] END ....KNN__n_neighbors=31, SCL=None;, score=-0.834 total time=   0.0s\n",
      "[CV 3/5] END ....KNN__n_neighbors=31, SCL=None;, score=-0.768 total time=   0.0s\n",
      "[CV 4/5] END ....KNN__n_neighbors=31, SCL=None;, score=-0.810 total time=   0.0s\n",
      "[CV 5/5] END ....KNN__n_neighbors=31, SCL=None;, score=-0.771 total time=   0.0s\n",
      "[CV 1/5] END KNN__n_neighbors=31, SCL=StandardScaler();, score=-0.665 total time=   0.3s\n",
      "[CV 2/5] END KNN__n_neighbors=31, SCL=StandardScaler();, score=-0.716 total time=   0.2s\n",
      "[CV 3/5] END KNN__n_neighbors=31, SCL=StandardScaler();, score=-0.723 total time=   0.2s\n",
      "[CV 4/5] END KNN__n_neighbors=31, SCL=StandardScaler();, score=-0.748 total time=   0.2s\n",
      "[CV 5/5] END KNN__n_neighbors=31, SCL=StandardScaler();, score=-0.694 total time=   0.2s\n",
      "[CV 1/5] END KNN__n_neighbors=31, SCL=MinMaxScaler();, score=-0.698 total time=   0.2s\n",
      "[CV 2/5] END KNN__n_neighbors=31, SCL=MinMaxScaler();, score=-0.735 total time=   0.1s\n",
      "[CV 3/5] END KNN__n_neighbors=31, SCL=MinMaxScaler();, score=-0.732 total time=   0.2s\n",
      "[CV 4/5] END KNN__n_neighbors=31, SCL=MinMaxScaler();, score=-0.758 total time=   0.2s\n",
      "[CV 5/5] END KNN__n_neighbors=31, SCL=MinMaxScaler();, score=-0.719 total time=   0.2s\n",
      "[CV 1/5] END ....KNN__n_neighbors=32, SCL=None;, score=-0.770 total time=   0.0s\n",
      "[CV 2/5] END ....KNN__n_neighbors=32, SCL=None;, score=-0.831 total time=   0.0s\n",
      "[CV 3/5] END ....KNN__n_neighbors=32, SCL=None;, score=-0.769 total time=   0.0s\n",
      "[CV 4/5] END ....KNN__n_neighbors=32, SCL=None;, score=-0.809 total time=   0.0s\n",
      "[CV 5/5] END ....KNN__n_neighbors=32, SCL=None;, score=-0.769 total time=   0.0s\n",
      "[CV 1/5] END KNN__n_neighbors=32, SCL=StandardScaler();, score=-0.669 total time=   0.2s\n",
      "[CV 2/5] END KNN__n_neighbors=32, SCL=StandardScaler();, score=-0.723 total time=   0.2s\n",
      "[CV 3/5] END KNN__n_neighbors=32, SCL=StandardScaler();, score=-0.734 total time=   0.3s\n",
      "[CV 4/5] END KNN__n_neighbors=32, SCL=StandardScaler();, score=-0.750 total time=   0.2s\n",
      "[CV 5/5] END KNN__n_neighbors=32, SCL=StandardScaler();, score=-0.694 total time=   0.2s\n",
      "[CV 1/5] END KNN__n_neighbors=32, SCL=MinMaxScaler();, score=-0.691 total time=   0.2s\n",
      "[CV 2/5] END KNN__n_neighbors=32, SCL=MinMaxScaler();, score=-0.731 total time=   0.2s\n",
      "[CV 3/5] END KNN__n_neighbors=32, SCL=MinMaxScaler();, score=-0.728 total time=   0.2s\n",
      "[CV 4/5] END KNN__n_neighbors=32, SCL=MinMaxScaler();, score=-0.756 total time=   0.1s\n",
      "[CV 5/5] END KNN__n_neighbors=32, SCL=MinMaxScaler();, score=-0.722 total time=   0.1s\n",
      "[CV 1/5] END ....KNN__n_neighbors=33, SCL=None;, score=-0.768 total time=   0.0s\n",
      "[CV 2/5] END ....KNN__n_neighbors=33, SCL=None;, score=-0.838 total time=   0.0s\n",
      "[CV 3/5] END ....KNN__n_neighbors=33, SCL=None;, score=-0.785 total time=   0.0s\n",
      "[CV 4/5] END ....KNN__n_neighbors=33, SCL=None;, score=-0.815 total time=   0.0s\n",
      "[CV 5/5] END ....KNN__n_neighbors=33, SCL=None;, score=-0.779 total time=   0.0s\n",
      "[CV 1/5] END KNN__n_neighbors=33, SCL=StandardScaler();, score=-0.673 total time=   0.2s\n",
      "[CV 2/5] END KNN__n_neighbors=33, SCL=StandardScaler();, score=-0.727 total time=   0.2s\n",
      "[CV 3/5] END KNN__n_neighbors=33, SCL=StandardScaler();, score=-0.730 total time=   0.2s\n",
      "[CV 4/5] END KNN__n_neighbors=33, SCL=StandardScaler();, score=-0.752 total time=   0.2s\n",
      "[CV 5/5] END KNN__n_neighbors=33, SCL=StandardScaler();, score=-0.694 total time=   0.2s\n",
      "[CV 1/5] END KNN__n_neighbors=33, SCL=MinMaxScaler();, score=-0.703 total time=   0.2s\n",
      "[CV 2/5] END KNN__n_neighbors=33, SCL=MinMaxScaler();, score=-0.730 total time=   0.1s\n",
      "[CV 3/5] END KNN__n_neighbors=33, SCL=MinMaxScaler();, score=-0.727 total time=   0.2s\n",
      "[CV 4/5] END KNN__n_neighbors=33, SCL=MinMaxScaler();, score=-0.755 total time=   0.2s\n",
      "[CV 5/5] END KNN__n_neighbors=33, SCL=MinMaxScaler();, score=-0.718 total time=   0.2s\n",
      "[CV 1/5] END ....KNN__n_neighbors=34, SCL=None;, score=-0.778 total time=   0.0s\n",
      "[CV 2/5] END ....KNN__n_neighbors=34, SCL=None;, score=-0.835 total time=   0.0s\n",
      "[CV 3/5] END ....KNN__n_neighbors=34, SCL=None;, score=-0.782 total time=   0.0s\n",
      "[CV 4/5] END ....KNN__n_neighbors=34, SCL=None;, score=-0.824 total time=   0.0s\n",
      "[CV 5/5] END ....KNN__n_neighbors=34, SCL=None;, score=-0.779 total time=   0.0s\n",
      "[CV 1/5] END KNN__n_neighbors=34, SCL=StandardScaler();, score=-0.684 total time=   0.2s\n",
      "[CV 2/5] END KNN__n_neighbors=34, SCL=StandardScaler();, score=-0.729 total time=   0.2s\n",
      "[CV 3/5] END KNN__n_neighbors=34, SCL=StandardScaler();, score=-0.732 total time=   0.3s\n",
      "[CV 4/5] END KNN__n_neighbors=34, SCL=StandardScaler();, score=-0.756 total time=   0.3s\n",
      "[CV 5/5] END KNN__n_neighbors=34, SCL=StandardScaler();, score=-0.696 total time=   0.3s\n",
      "[CV 1/5] END KNN__n_neighbors=34, SCL=MinMaxScaler();, score=-0.693 total time=   0.2s\n",
      "[CV 2/5] END KNN__n_neighbors=34, SCL=MinMaxScaler();, score=-0.738 total time=   0.2s\n",
      "[CV 3/5] END KNN__n_neighbors=34, SCL=MinMaxScaler();, score=-0.724 total time=   0.2s\n",
      "[CV 4/5] END KNN__n_neighbors=34, SCL=MinMaxScaler();, score=-0.756 total time=   0.1s\n",
      "[CV 5/5] END KNN__n_neighbors=34, SCL=MinMaxScaler();, score=-0.721 total time=   0.1s\n",
      "[CV 1/5] END ....KNN__n_neighbors=35, SCL=None;, score=-0.777 total time=   0.0s\n",
      "[CV 2/5] END ....KNN__n_neighbors=35, SCL=None;, score=-0.834 total time=   0.0s\n",
      "[CV 3/5] END ....KNN__n_neighbors=35, SCL=None;, score=-0.789 total time=   0.0s\n",
      "[CV 4/5] END ....KNN__n_neighbors=35, SCL=None;, score=-0.831 total time=   0.0s\n",
      "[CV 5/5] END ....KNN__n_neighbors=35, SCL=None;, score=-0.783 total time=   0.0s\n",
      "[CV 1/5] END KNN__n_neighbors=35, SCL=StandardScaler();, score=-0.680 total time=   0.2s\n",
      "[CV 2/5] END KNN__n_neighbors=35, SCL=StandardScaler();, score=-0.733 total time=   0.2s\n",
      "[CV 3/5] END KNN__n_neighbors=35, SCL=StandardScaler();, score=-0.730 total time=   0.2s\n",
      "[CV 4/5] END KNN__n_neighbors=35, SCL=StandardScaler();, score=-0.751 total time=   0.3s\n",
      "[CV 5/5] END KNN__n_neighbors=35, SCL=StandardScaler();, score=-0.697 total time=   0.3s\n",
      "[CV 1/5] END KNN__n_neighbors=35, SCL=MinMaxScaler();, score=-0.711 total time=   0.2s\n",
      "[CV 2/5] END KNN__n_neighbors=35, SCL=MinMaxScaler();, score=-0.743 total time=   0.2s\n",
      "[CV 3/5] END KNN__n_neighbors=35, SCL=MinMaxScaler();, score=-0.720 total time=   0.2s\n",
      "[CV 4/5] END KNN__n_neighbors=35, SCL=MinMaxScaler();, score=-0.757 total time=   0.2s\n",
      "[CV 5/5] END KNN__n_neighbors=35, SCL=MinMaxScaler();, score=-0.711 total time=   0.2s\n",
      "[CV 1/5] END ....KNN__n_neighbors=36, SCL=None;, score=-0.781 total time=   0.0s\n",
      "[CV 2/5] END ....KNN__n_neighbors=36, SCL=None;, score=-0.840 total time=   0.0s\n",
      "[CV 3/5] END ....KNN__n_neighbors=36, SCL=None;, score=-0.783 total time=   0.0s\n",
      "[CV 4/5] END ....KNN__n_neighbors=36, SCL=None;, score=-0.828 total time=   0.0s\n",
      "[CV 5/5] END ....KNN__n_neighbors=36, SCL=None;, score=-0.783 total time=   0.0s\n",
      "[CV 1/5] END KNN__n_neighbors=36, SCL=StandardScaler();, score=-0.676 total time=   0.2s\n",
      "[CV 2/5] END KNN__n_neighbors=36, SCL=StandardScaler();, score=-0.724 total time=   0.2s\n",
      "[CV 3/5] END KNN__n_neighbors=36, SCL=StandardScaler();, score=-0.731 total time=   0.3s\n",
      "[CV 4/5] END KNN__n_neighbors=36, SCL=StandardScaler();, score=-0.742 total time=   0.3s\n",
      "[CV 5/5] END KNN__n_neighbors=36, SCL=StandardScaler();, score=-0.694 total time=   0.2s\n",
      "[CV 1/5] END KNN__n_neighbors=36, SCL=MinMaxScaler();, score=-0.697 total time=   0.2s\n",
      "[CV 2/5] END KNN__n_neighbors=36, SCL=MinMaxScaler();, score=-0.732 total time=   0.2s\n",
      "[CV 3/5] END KNN__n_neighbors=36, SCL=MinMaxScaler();, score=-0.728 total time=   0.2s\n",
      "[CV 4/5] END KNN__n_neighbors=36, SCL=MinMaxScaler();, score=-0.747 total time=   0.2s\n",
      "[CV 5/5] END KNN__n_neighbors=36, SCL=MinMaxScaler();, score=-0.717 total time=   0.2s\n",
      "[CV 1/5] END ....KNN__n_neighbors=37, SCL=None;, score=-0.778 total time=   0.0s\n",
      "[CV 2/5] END ....KNN__n_neighbors=37, SCL=None;, score=-0.838 total time=   0.0s\n",
      "[CV 3/5] END ....KNN__n_neighbors=37, SCL=None;, score=-0.778 total time=   0.0s\n",
      "[CV 4/5] END ....KNN__n_neighbors=37, SCL=None;, score=-0.827 total time=   0.0s\n",
      "[CV 5/5] END ....KNN__n_neighbors=37, SCL=None;, score=-0.797 total time=   0.0s\n",
      "[CV 1/5] END KNN__n_neighbors=37, SCL=StandardScaler();, score=-0.678 total time=   0.2s\n",
      "[CV 2/5] END KNN__n_neighbors=37, SCL=StandardScaler();, score=-0.741 total time=   0.3s\n",
      "[CV 3/5] END KNN__n_neighbors=37, SCL=StandardScaler();, score=-0.738 total time=   0.3s\n",
      "[CV 4/5] END KNN__n_neighbors=37, SCL=StandardScaler();, score=-0.743 total time=   0.2s\n",
      "[CV 5/5] END KNN__n_neighbors=37, SCL=StandardScaler();, score=-0.705 total time=   0.2s\n",
      "[CV 1/5] END KNN__n_neighbors=37, SCL=MinMaxScaler();, score=-0.703 total time=   0.2s\n",
      "[CV 2/5] END KNN__n_neighbors=37, SCL=MinMaxScaler();, score=-0.739 total time=   0.2s\n",
      "[CV 3/5] END KNN__n_neighbors=37, SCL=MinMaxScaler();, score=-0.732 total time=   0.2s\n",
      "[CV 4/5] END KNN__n_neighbors=37, SCL=MinMaxScaler();, score=-0.746 total time=   0.2s\n",
      "[CV 5/5] END KNN__n_neighbors=37, SCL=MinMaxScaler();, score=-0.732 total time=   0.2s\n",
      "[CV 1/5] END ....KNN__n_neighbors=38, SCL=None;, score=-0.775 total time=   0.0s\n",
      "[CV 2/5] END ....KNN__n_neighbors=38, SCL=None;, score=-0.832 total time=   0.0s\n",
      "[CV 3/5] END ....KNN__n_neighbors=38, SCL=None;, score=-0.779 total time=   0.0s\n",
      "[CV 4/5] END ....KNN__n_neighbors=38, SCL=None;, score=-0.834 total time=   0.0s\n",
      "[CV 5/5] END ....KNN__n_neighbors=38, SCL=None;, score=-0.787 total time=   0.0s\n",
      "[CV 1/5] END KNN__n_neighbors=38, SCL=StandardScaler();, score=-0.680 total time=   0.2s\n",
      "[CV 2/5] END KNN__n_neighbors=38, SCL=StandardScaler();, score=-0.739 total time=   0.2s\n",
      "[CV 3/5] END KNN__n_neighbors=38, SCL=StandardScaler();, score=-0.734 total time=   0.3s\n",
      "[CV 4/5] END KNN__n_neighbors=38, SCL=StandardScaler();, score=-0.747 total time=   0.2s\n",
      "[CV 5/5] END KNN__n_neighbors=38, SCL=StandardScaler();, score=-0.697 total time=   0.3s\n",
      "[CV 1/5] END KNN__n_neighbors=38, SCL=MinMaxScaler();, score=-0.695 total time=   0.2s\n",
      "[CV 2/5] END KNN__n_neighbors=38, SCL=MinMaxScaler();, score=-0.739 total time=   0.2s\n",
      "[CV 3/5] END KNN__n_neighbors=38, SCL=MinMaxScaler();, score=-0.734 total time=   0.2s\n",
      "[CV 4/5] END KNN__n_neighbors=38, SCL=MinMaxScaler();, score=-0.758 total time=   0.1s\n",
      "[CV 5/5] END KNN__n_neighbors=38, SCL=MinMaxScaler();, score=-0.724 total time=   0.2s\n",
      "[CV 1/5] END ....KNN__n_neighbors=39, SCL=None;, score=-0.782 total time=   0.0s\n",
      "[CV 2/5] END ....KNN__n_neighbors=39, SCL=None;, score=-0.831 total time=   0.0s\n",
      "[CV 3/5] END ....KNN__n_neighbors=39, SCL=None;, score=-0.782 total time=   0.0s\n",
      "[CV 4/5] END ....KNN__n_neighbors=39, SCL=None;, score=-0.828 total time=   0.0s\n",
      "[CV 5/5] END ....KNN__n_neighbors=39, SCL=None;, score=-0.782 total time=   0.0s\n",
      "[CV 1/5] END KNN__n_neighbors=39, SCL=StandardScaler();, score=-0.678 total time=   0.2s\n",
      "[CV 2/5] END KNN__n_neighbors=39, SCL=StandardScaler();, score=-0.737 total time=   0.2s\n",
      "[CV 3/5] END KNN__n_neighbors=39, SCL=StandardScaler();, score=-0.732 total time=   0.3s\n",
      "[CV 4/5] END KNN__n_neighbors=39, SCL=StandardScaler();, score=-0.744 total time=   0.3s\n",
      "[CV 5/5] END KNN__n_neighbors=39, SCL=StandardScaler();, score=-0.700 total time=   0.2s\n",
      "[CV 1/5] END KNN__n_neighbors=39, SCL=MinMaxScaler();, score=-0.696 total time=   0.2s\n",
      "[CV 2/5] END KNN__n_neighbors=39, SCL=MinMaxScaler();, score=-0.742 total time=   0.1s\n",
      "[CV 3/5] END KNN__n_neighbors=39, SCL=MinMaxScaler();, score=-0.731 total time=   0.2s\n",
      "[CV 4/5] END KNN__n_neighbors=39, SCL=MinMaxScaler();, score=-0.763 total time=   0.2s\n",
      "[CV 5/5] END KNN__n_neighbors=39, SCL=MinMaxScaler();, score=-0.726 total time=   0.3s\n",
      "{'KNN__n_neighbors': 22, 'SCL': StandardScaler()}\n",
      "-0.6950000000000001\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mm_scaler=MinMaxScaler()\n",
    "std_scaler=StandardScaler()\n",
    "knn =KNeighborsRegressor()\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "params={\"KNN__n_neighbors\":np.arange(1,40),\"SCL\":[None,std_scaler,mm_scaler]}\n",
    "\n",
    "pipe=Pipeline([(\"SCL\",None),(\"KNN\",knn)])\n",
    "\n",
    "kfold=KFold(n_splits=5,shuffle=True,random_state=24)\n",
    "\n",
    "gcv=GridSearchCV(pipe,param_grid=params,cv=kfold,verbose=3,scoring=\"neg_median_absolute_error\")\n",
    "gcv.fit(x,y)\n",
    "\n",
    "print(gcv.best_params_)\n",
    "print(gcv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1c38ae4-f547-4ba5-83a5-49dea19f98db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## inferencing\n",
    "test=pd.read_csv(\"test.csv\",index_col=0)\n",
    "best_model=gcv.best_estimator_\n",
    "pred_hard=best_model.predict(test)\n",
    "submit=pd.read_csv(\"sample_submission.csv\")\n",
    "submit[\"Hardness\"]=pred_hard\n",
    "submit.to_csv(\"submission_f111.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c67687f-ff7a-4215-8886-3f2969502923",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
